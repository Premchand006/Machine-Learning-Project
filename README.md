# ğŸŒ Solar Irradiance Prediction using Machine Learning  

## ğŸ“Œ Overview  
This project implements a **machine learning pipeline** to predict **solar irradiance** using regression models such as **Linear Regression** and **XGBoost**. The approach includes **data preprocessing, feature engineering, model training, hyperparameter tuning, and evaluation** using various performance metrics.  

## ğŸš€ Features  
âœ… **Data Preprocessing:** Handling missing values, scaling, and feature engineering  
âœ… **Machine Learning Models:** Linear Regression, XGBoost  
âœ… **Hyperparameter Optimization:** Using `RandomizedSearchCV`  
âœ… **Model Evaluation:** RMSE, RÂ² Score, MAE for performance assessment  
âœ… **Visualization:** `matplotlib` & `seaborn` for graphical analysis  
âœ… **Feature Importance Analysis:** Using **SHAP** for explainability  

---

## ğŸ“‚ Project Structure  
```
ğŸ“¦ Solar_Irradiance_Prediction
â”‚â”€â”€ ğŸ“œ final.ipynb              # Jupyter Notebook containing the full workflow
â”‚â”€â”€ ğŸ“‚ data/                    # Dataset directory (training & test data)
â”‚â”€â”€ ğŸ“‚ models/                  # Saved trained models (optional)
â”‚â”€â”€ ğŸ“‚ results/                 # Visualizations & analysis outputs
â”‚â”€â”€ ğŸ“œ README.md                # Project documentation
```

---

## ğŸ›  Installation & Setup  
### 1ï¸âƒ£ **Clone the Repository**  
```bash
git clone https://github.com/your-repo/solar-irradiance-ml.git
cd solar-irradiance-ml
```

### 2ï¸âƒ£ **Install Dependencies**  
Ensure you have **Python 3.8+** installed, then install the required packages:  
```bash
pip install -r requirements.txt
```
If `requirements.txt` is missing, install manually:  
```bash
pip install numpy pandas matplotlib seaborn scikit-learn xgboost shap jupyter
```

### 3ï¸âƒ£ **Run the Jupyter Notebook**  
```bash
jupyter notebook final.ipynb
```

---

## ğŸ“Š Data Processing & Model Training  
1ï¸âƒ£ **Load Dataset** â€“ Read training and testing data from CSV  
2ï¸âƒ£ **Preprocessing** â€“ Handle missing values, standardize features  
3ï¸âƒ£ **Feature Engineering** â€“ Apply transformations and create new features  
4ï¸âƒ£ **Model Selection** â€“ Train **Linear Regression** and **XGBoost** models  
5ï¸âƒ£ **Hyperparameter Tuning** â€“ Use `RandomizedSearchCV` for optimization  
6ï¸âƒ£ **Model Evaluation** â€“ Compute RMSE, RÂ², and visualize performance  
7ï¸âƒ£ **Feature Importance** â€“ Apply **SHAP** to interpret model decisions  

---

## ğŸ¯ Model Evaluation Metrics  
The model is evaluated based on the following:  
âœ” **Root Mean Squared Error (RMSE)** â€“ Measures error magnitude  
âœ” **RÂ² Score (Coefficient of Determination)** â€“ Indicates goodness of fit  
âœ” **Mean Absolute Error (MAE)** â€“ Measures absolute prediction errors  

Example Output (Replace with actual results):
| Model            | RMSE  | RÂ² Score | MAE  |
|-----------------|------:|---------:|-----:|
| Linear Regression | 3.24  | 0.85     | 2.15 |
| XGBoost         | 2.58  | 0.92     | 1.75 |

---

## ğŸ“ˆ Visualizations  
The project includes **data insights and model evaluation graphs**, such as:  
ğŸ“Œ **Feature Correlations** â€“ Understanding data relationships  
ğŸ“Œ **Actual vs. Predicted Scatter Plots** â€“ Model accuracy representation  
ğŸ“Œ **SHAP Interpretability Plots** â€“ Feature impact on predictions  

Example:  
```python
import shap
explainer = shap.Explainer(xgb_model)
shap_values = explainer(X_test)
shap.summary_plot(shap_values, X_test)
```
